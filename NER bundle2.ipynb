{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {   \n",
    "    'input_path': \"test_data/HIPE-data-v1.2-test-masked-de.tsv\",\n",
    "#     'models':  [\"ner-french-8-europeana\", \"ner-french-5-europeana\", \n",
    "#               \"ner-french-8\", \"ner-french-5\"],\n",
    "    \n",
    "    'models': ['ner-german-5', 'ner-german-5-europeana'],\n",
    "    'vote_threshold': 2,\n",
    "    'tokenizer': \"bert-base-multilingual-cased\",\n",
    "    'output_path': \"first_submissions/UvA.ILPS_bundle2_DE_2.tsv.nerc_only\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"/ivi/ilps/personal/vprovat/good_models_for_clef/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = config['input_path']\n",
    "\n",
    "MODELS = [PREFIX + model for model in config['models']]\n",
    "\n",
    "VOTE_THRESHOLD = config['vote_threshold']\n",
    "\n",
    "TOKENIZER = config['tokenizer']\n",
    "\n",
    "OUTPUT_PATH = config['output_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0: reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_processing import read_data_to_dfs, write_results, add_beginnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = FILE_PATH.split('/')[-1]\n",
    "# pickle.dump(dfs, open('pickles/'+filename+'.p', 'wb'))\n",
    "dfs = pickle.load(open('pickles/'+filename+'.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = read_data_to_dfs(FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER)\n",
    "\n",
    "label_list = [\n",
    "    'B-loc',\n",
    "    'B-org',\n",
    "    'B-pers',\n",
    "    'B-prod',\n",
    "    'B-time',\n",
    "    'I-loc',\n",
    "    'I-org',\n",
    "    'I-pers',\n",
    "    'I-prod',\n",
    "    'I-time',\n",
    "    'O'\n",
    "]\n",
    "\n",
    "models = [AutoModelForTokenClassification.from_pretrained(MODEL_NAME) for MODEL_NAME in MODELS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(sequence, model_):\n",
    "    tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n",
    "    inputs = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "\n",
    "    # print([(a, b) for a, b in (zip(tokens,inputs[0]))])\n",
    "\n",
    "    outputs = model_(inputs)\n",
    "    # print(outputs)\n",
    "    predictions = torch.argmax(outputs[0], dim=2)\n",
    "    \n",
    "    nice_predictions = [(token, label_list[prediction]) for token, prediction in zip(tokens, predictions[0].tolist())]\n",
    "    return nice_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize_predictions(predictions):\n",
    "    cur_token = ''\n",
    "    cur_label = ''\n",
    "    res = []\n",
    "    for token, label in predictions:\n",
    "        if token[0] == '[':\n",
    "            continue\n",
    "        if token[0] == '#':\n",
    "            cur_token += token.strip('#')\n",
    "            cur_label = label\n",
    "        else:\n",
    "            if cur_token:\n",
    "                res.append((cur_token, cur_label))\n",
    "            cur_token = token\n",
    "            cur_label = label\n",
    "            \n",
    "    if cur_token:\n",
    "        res.append((cur_token, cur_label))        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_df(df, model_):\n",
    "    sequence = \" \".join(df['TOKEN'].tolist())\n",
    "    \n",
    "    predictions_raw = get_predictions(sequence, model_)\n",
    "    predictions = detokenize_predictions(predictions_raw)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Neuigkeiten', 'O'), ('.', 'O'), ('(', 'O'), ('Mißhandlung', 'O'), ('der', 'O'), ('Franken', 'O'), ('in', 'O'), ('Rom', 'B-loc'), ('.', 'O'), (']', 'O'), ('Buonaparte', 'I-pers'), (\"'\", 'O'), ('s', 'O'), ('Bruder', 'O'), ('hat', 'O')]\n",
      "+\n",
      "[('Neuigkeiten', 'O'), ('.', 'O'), ('(', 'O'), ('Mißhandlung', 'O'), ('der', 'O'), ('Franken', 'O'), ('in', 'O'), ('Rom', 'B-loc'), ('.', 'O'), (']', 'O'), ('Buonaparte', 'I-pers'), (\"'\", 'O'), ('s', 'O'), ('Bruder', 'O'), ('hat', 'O')]\n",
      "+\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(predict_for_df(dfs[0], model))\n",
    "    print('+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_predictions(preds):\n",
    "    zipped = [[] for i in range(len(preds[0]))]\n",
    "    for p in preds:\n",
    "        for i, item in enumerate(p):\n",
    "            zipped[i].append(item)\n",
    "            \n",
    "    return zipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter \n",
    "\n",
    "def find_best_label(labels): # not using VOTE_THRESHOLD yet\n",
    "    candidates = []\n",
    "    counter = Counter(labels).most_common()\n",
    "    top_votes = counter[0][-1] # (first_label, number_votes) -> number_votes\n",
    "    \n",
    "    candidates = [label for label, cnt in counter if cnt == top_votes]\n",
    "    return random.choice(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions(pred_list):\n",
    "    res = []\n",
    "    zipped_preds = zip_predictions(pred_list)\n",
    "    for preds in zipped_preds: # list of M (token, label) pairs, where label is predicted by each of M models\n",
    "#         print(preds)\n",
    "        token = preds[0][0]\n",
    "        labels = [pred[-1] for pred in preds]\n",
    "        best_label = find_best_label(labels)\n",
    "        res.append((token, best_label))\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions_to_df(df, target_column='NE-COARSE-LIT'):\n",
    "    \n",
    "    all_predictions = [predict_for_df(df, model) for model in models]\n",
    "    \n",
    "    best_predictions = combine_predictions(all_predictions)\n",
    "    res_df = df.copy()\n",
    "    for i, (token, label) in enumerate(best_predictions):\n",
    "        res_df[target_column][i] = label\n",
    "        \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOKEN</th>\n",
       "      <th>NE-COARSE-LIT</th>\n",
       "      <th>NE-COARSE-METO</th>\n",
       "      <th>NE-FINE-LIT</th>\n",
       "      <th>NE-FINE-METO</th>\n",
       "      <th>NE-FINE-COMP</th>\n",
       "      <th>NE-NESTED</th>\n",
       "      <th>NEL-LIT</th>\n",
       "      <th>NEL-METO</th>\n",
       "      <th>MISC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>die</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neulich</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>schon</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>erzählten</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vorfälle</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rom</td>\n",
       "      <td>B-loc</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ans</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>EndOfLine|NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Directorium</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>berichtet</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>und</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>die</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>verdächtige</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Weise</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>EndOfLine|NoSpaceAfter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TOKEN NE-COARSE-LIT NE-COARSE-METO NE-FINE-LIT NE-FINE-METO  \\\n",
       "0           die             O              _           _            _   \n",
       "1       neulich             O              _           _            _   \n",
       "2         schon             O              _           _            _   \n",
       "3     erzählten             O              _           _            _   \n",
       "4      Vorfälle             O              _           _            _   \n",
       "5            in             O              _           _            _   \n",
       "6           Rom         B-loc              _           _            _   \n",
       "7           ans             O              _           _            _   \n",
       "8   Directorium             O              _           _            _   \n",
       "9     berichtet             O              _           _            _   \n",
       "10            ,             O              _           _            _   \n",
       "11          und             O              _           _            _   \n",
       "12          die             O              _           _            _   \n",
       "13  verdächtige             O              _           _            _   \n",
       "14        Weise             O              _           _            _   \n",
       "15            ,             O              _           _            _   \n",
       "\n",
       "   NE-FINE-COMP NE-NESTED NEL-LIT NEL-METO                    MISC  \n",
       "0             _         _       _        _                       _  \n",
       "1             _         _       _        _                       _  \n",
       "2             _         _       _        _                       _  \n",
       "3             _         _       _        _                       _  \n",
       "4             _         _       _        _                       _  \n",
       "5             _         _       _        _                       _  \n",
       "6             _         _       _        _                       _  \n",
       "7             _         _       _        _  EndOfLine|NoSpaceAfter  \n",
       "8             _         _       _        _                       _  \n",
       "9             _         _       _        _            NoSpaceAfter  \n",
       "10            _         _       _        _                       _  \n",
       "11            _         _       _        _                       _  \n",
       "12            _         _       _        _                       _  \n",
       "13            _         _       _        _                       _  \n",
       "14            _         _       _        _            NoSpaceAfter  \n",
       "15            _         _       _        _  EndOfLine|NoSpaceAfter  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_predictions_to_df(dfs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOKEN</th>\n",
       "      <th>NE-COARSE-LIT</th>\n",
       "      <th>NE-COARSE-METO</th>\n",
       "      <th>NE-FINE-LIT</th>\n",
       "      <th>NE-FINE-METO</th>\n",
       "      <th>NE-FINE-COMP</th>\n",
       "      <th>NE-NESTED</th>\n",
       "      <th>NEL-LIT</th>\n",
       "      <th>NEL-METO</th>\n",
       "      <th>MISC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>die</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neulich</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>schon</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>erzählten</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vorfälle</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rom</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ans</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>EndOfLine|NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Directorium</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>berichtet</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>,</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>und</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>die</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>verdächtige</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Weise</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>,</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>EndOfLine|NoSpaceAfter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TOKEN NE-COARSE-LIT NE-COARSE-METO NE-FINE-LIT NE-FINE-METO  \\\n",
       "0           die             _              _           _            _   \n",
       "1       neulich             _              _           _            _   \n",
       "2         schon             _              _           _            _   \n",
       "3     erzählten             _              _           _            _   \n",
       "4      Vorfälle             _              _           _            _   \n",
       "5            in             _              _           _            _   \n",
       "6           Rom             _              _           _            _   \n",
       "7           ans             _              _           _            _   \n",
       "8   Directorium             _              _           _            _   \n",
       "9     berichtet             _              _           _            _   \n",
       "10            ,             _              _           _            _   \n",
       "11          und             _              _           _            _   \n",
       "12          die             _              _           _            _   \n",
       "13  verdächtige             _              _           _            _   \n",
       "14        Weise             _              _           _            _   \n",
       "15            ,             _              _           _            _   \n",
       "\n",
       "   NE-FINE-COMP NE-NESTED NEL-LIT NEL-METO                    MISC  \n",
       "0             _         _       _        _                       _  \n",
       "1             _         _       _        _                       _  \n",
       "2             _         _       _        _                       _  \n",
       "3             _         _       _        _                       _  \n",
       "4             _         _       _        _                       _  \n",
       "5             _         _       _        _                       _  \n",
       "6             _         _       _        _                       _  \n",
       "7             _         _       _        _  EndOfLine|NoSpaceAfter  \n",
       "8             _         _       _        _                       _  \n",
       "9             _         _       _        _            NoSpaceAfter  \n",
       "10            _         _       _        _                       _  \n",
       "11            _         _       _        _                       _  \n",
       "12            _         _       _        _                       _  \n",
       "13            _         _       _        _                       _  \n",
       "14            _         _       _        _            NoSpaceAfter  \n",
       "15            _         _       _        _  EndOfLine|NoSpaceAfter  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_with_predictions = [add_predictions_to_df(df) for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOKEN</th>\n",
       "      <th>NE-COARSE-LIT</th>\n",
       "      <th>NE-COARSE-METO</th>\n",
       "      <th>NE-FINE-LIT</th>\n",
       "      <th>NE-FINE-METO</th>\n",
       "      <th>NE-FINE-COMP</th>\n",
       "      <th>NE-NESTED</th>\n",
       "      <th>NEL-LIT</th>\n",
       "      <th>NEL-METO</th>\n",
       "      <th>MISC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>die</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neulich</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>schon</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>erzählten</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vorfälle</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rom</td>\n",
       "      <td>B-loc</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ans</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>EndOfLine|NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Directorium</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>berichtet</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>und</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>die</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>verdächtige</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Weise</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>EndOfLine|NoSpaceAfter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TOKEN NE-COARSE-LIT NE-COARSE-METO NE-FINE-LIT NE-FINE-METO  \\\n",
       "0           die             O              _           _            _   \n",
       "1       neulich             O              _           _            _   \n",
       "2         schon             O              _           _            _   \n",
       "3     erzählten             O              _           _            _   \n",
       "4      Vorfälle             O              _           _            _   \n",
       "5            in             O              _           _            _   \n",
       "6           Rom         B-loc              _           _            _   \n",
       "7           ans             O              _           _            _   \n",
       "8   Directorium             O              _           _            _   \n",
       "9     berichtet             O              _           _            _   \n",
       "10            ,             O              _           _            _   \n",
       "11          und             O              _           _            _   \n",
       "12          die             O              _           _            _   \n",
       "13  verdächtige             O              _           _            _   \n",
       "14        Weise             O              _           _            _   \n",
       "15            ,             O              _           _            _   \n",
       "\n",
       "   NE-FINE-COMP NE-NESTED NEL-LIT NEL-METO                    MISC  \n",
       "0             _         _       _        _                       _  \n",
       "1             _         _       _        _                       _  \n",
       "2             _         _       _        _                       _  \n",
       "3             _         _       _        _                       _  \n",
       "4             _         _       _        _                       _  \n",
       "5             _         _       _        _                       _  \n",
       "6             _         _       _        _                       _  \n",
       "7             _         _       _        _  EndOfLine|NoSpaceAfter  \n",
       "8             _         _       _        _                       _  \n",
       "9             _         _       _        _            NoSpaceAfter  \n",
       "10            _         _       _        _                       _  \n",
       "11            _         _       _        _                       _  \n",
       "12            _         _       _        _                       _  \n",
       "13            _         _       _        _                       _  \n",
       "14            _         _       _        _            NoSpaceAfter  \n",
       "15            _         _       _        _  EndOfLine|NoSpaceAfter  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_with_predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.data_processing import add_beginnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_with_beginnings = [add_beginnings(add_predictions_to_df(df)) for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "run_name = OUTPUT_PATH.split('/')[-1]\n",
    "folder = OUTPUT_PATH.split('/')[0]\n",
    "pickle_path = folder + '/pickles/' + run_name + '.p'\n",
    "\n",
    "pickle.dump(dfs_with_predictions, open(pickle_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_results(dfs_with_predictions, OUTPUT_PATH)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTEST_bundle2_FR_1 – no Europeana yet, 10 epochs\\nTEST_bundle2_FR_2 – with Europeana, 5 epochs\\nTEST_bundle2_FR_3 – no Europeana, 5 epochs - just to compare\\n\\nTEST_bundle2_FR_4 – no Europeana, 8 epochs (it was the best for FR so far)\\nTEST_bundle2_FR_5 – with Europeana, 8 epochs - is it better?\\n\\nTEST_bundle2_DE_2 – with Europeana, 5 epochs\\nTEST_bundle2_DE_3 – no Europeana, 7 epochs\\nTEST_bundle4_DE_4 – with Europeana, 7 epochs\\n\\n\\nTEST_bundle2_EN_1 – BERT finetuned on conll English\\n\\n'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "TEST_bundle2_FR_1 – no Europeana yet, 10 epochs\n",
    "TEST_bundle2_FR_2 – with Europeana, 5 epochs\n",
    "TEST_bundle2_FR_3 – no Europeana, 5 epochs - just to compare\n",
    "\n",
    "TEST_bundle2_FR_4 – no Europeana, 8 epochs (it was the best for FR so far)\n",
    "TEST_bundle2_FR_5 – with Europeana, 8 epochs - is it better? probably yes!\n",
    "\n",
    "testing_submissions/TEST_bundle2_FR_6 – ensembling: 5 or 8 epochs, with or without Europeana\n",
    "\n",
    "TEST_bundle2_DE_2 – with Europeana, 5 epochs\n",
    "TEST_bundle2_DE_3 – no Europeana, 7 epochs\n",
    "TEST_bundle4_DE_4 – with Europeana, 7 epochs\n",
    "\n",
    "\n",
    "TEST_bundle2_EN_1 – BERT finetuned on conll English\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (transformers)",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
