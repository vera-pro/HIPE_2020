{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_path': \"first_submissions/UvA.ILPS_bundle2_FR_2.tsv.mentions_only\",\n",
    "    'output_path': \"first_submissions/UvA.ILPS_bundle2_FR_2.tsv.nel_only\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = config['input_path']\n",
    "\n",
    "OUTPUT_PATH = config['output_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0: reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_processing import read_data_to_dfs, write_results, add_beginnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def get_dfs(path):\n",
    "    try:\n",
    "        run_name = path.split('/')[-1]\n",
    "        folder = path.split('/')[0]\n",
    "        pickle_path = folder + '/pickles/' + run_name + '.p'\n",
    "#         print(pickle_path)\n",
    "        dfs = pickle.load(open(pickle_path, 'rb'))\n",
    "    except Exception:\n",
    "        print('pickled file not found')\n",
    "        dfs = read_data_to_dfs(path)\n",
    "        \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_with_predictions = get_dfs(FILE_PATH)\n",
    "\n",
    "# import pickle\n",
    "# dfs_with_predictions = pickle.load(open(FILE_PATH+'.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOKEN</th>\n",
       "      <th>NE-COARSE-LIT</th>\n",
       "      <th>NE-COARSE-METO</th>\n",
       "      <th>NE-FINE-LIT</th>\n",
       "      <th>NE-FINE-METO</th>\n",
       "      <th>NE-FINE-COMP</th>\n",
       "      <th>NE-NESTED</th>\n",
       "      <th>NEL-LIT</th>\n",
       "      <th>NEL-METO</th>\n",
       "      <th>MISC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quarantaines</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>des</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ports</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>B-ent</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>et</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Italie</td>\n",
       "      <td>B-ent</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>si</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nuisibles</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>au</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>commerce</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>de</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>EndOfLine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TOKEN NE-COARSE-LIT NE-COARSE-METO NE-FINE-LIT NE-FINE-METO  \\\n",
       "0   quarantaines             O              _           _            _   \n",
       "1            des             O              _           _            _   \n",
       "2          ports             O              _           _            _   \n",
       "3             de             O              _           _            _   \n",
       "4         France         B-ent              _           _            _   \n",
       "5             et             O              _           _            _   \n",
       "6              d             O              _           _            _   \n",
       "7              '             O              _           _            _   \n",
       "8         Italie         B-ent              _           _            _   \n",
       "9             si             O              _           _            _   \n",
       "10     nuisibles             O              _           _            _   \n",
       "11            au             O              _           _            _   \n",
       "12      commerce             O              _           _            _   \n",
       "13            de             O              _           _            _   \n",
       "\n",
       "   NE-FINE-COMP NE-NESTED NEL-LIT NEL-METO          MISC  \n",
       "0             _         _       _        _             _  \n",
       "1             _         _       _        _             _  \n",
       "2             _         _       _        _             _  \n",
       "3             _         _       _        _             _  \n",
       "4             _         _       _        _             _  \n",
       "5             _         _       _        _             _  \n",
       "6             _         _       _        _  NoSpaceAfter  \n",
       "7             _         _       _        _  NoSpaceAfter  \n",
       "8             _         _       _        _             _  \n",
       "9             _         _       _        _             _  \n",
       "10            _         _       _        _             _  \n",
       "11            _         _       _        _             _  \n",
       "12            _         _       _        _             _  \n",
       "13            _         _       _        _     EndOfLine  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_with_predictions[1145]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 'France'), (8, 'Italie')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_entity_mentions(dfs_with_predictions[1145])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: NEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(timeout=30, max_retries=10, retry_on_timeout=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ilps-cn001',\n",
       " 'cluster_name': 'elasticsearch',\n",
       " 'cluster_uuid': 'vU7MO42lR2KzA6bPvSP_pA',\n",
       " 'version': {'number': '7.7.0',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'tar',\n",
       "  'build_hash': '81a1e9eda8e6183f5237786246f6dced26a10eaf',\n",
       "  'build_date': '2020-05-12T02:01:37.602180Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '8.5.1',\n",
       "  'minimum_wire_compatibility_version': '6.8.0',\n",
       "  'minimum_index_compatibility_version': '6.0.0-beta1'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_processing import extract_entity_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.elastic_getters import wikidata_search_, wikidata_search_precise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for an entity\n",
    "def get_wikidata_entries(es, entity):\n",
    "    hits = wikidata_search_(es, entity)\n",
    "    hits_exact = wikidata_search_precise(es, entity)\n",
    "    \n",
    "    if len(hits) + len(hits_exact) == 0:\n",
    "        return \"NIL\"\n",
    "    \n",
    "    answer_length = min(5, len(hits_exact))\n",
    "    results = [hit['_source']['label_exact'] for hit in hits_exact[:answer_length]]\n",
    "    remaining_length = 5 - answer_length\n",
    "    \n",
    "    if remaining_length > 0:\n",
    "        results.append('NIL')\n",
    "        remaining_length -= 1\n",
    "        \n",
    "    remaining_hits = [hit for hit in hits if hit['_source']['label_exact'] not in results]\n",
    "    \n",
    "\n",
    "    if remaining_length > 0:\n",
    "        remaining_hits_sorted = sorted(remaining_hits, key=lambda x: (-x['_score'], len(x['_source']['label_exact']), x['_source']['count']))\n",
    "        cnt = 0\n",
    "        while remaining_length > 0 and cnt < len(remaining_hits_sorted):\n",
    "            results.append(remaining_hits_sorted[cnt]['_source']['label_exact'])\n",
    "            cnt += 1\n",
    "            remaining_length -= 1\n",
    "            \n",
    "    return '|'.join(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_links(df, ner_column='NE-COARSE-LIT', nel_column='NEL-LIT'):\n",
    "    res_df = df.copy()\n",
    "    true_labels = df[nel_column].tolist()\n",
    "    mentions = extract_entity_mentions(df, ner_column)\n",
    "    \n",
    "    for position, mention in mentions:\n",
    "        labels = get_wikidata_entries(es, mention)\n",
    "        cur_pos = position\n",
    "        num_words = len(mention.split())\n",
    "        while cur_pos - position < num_words:\n",
    "            res_df[nel_column][cur_pos] = labels\n",
    "            cur_pos += 1\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOKEN</th>\n",
       "      <th>NE-COARSE-LIT</th>\n",
       "      <th>NE-COARSE-METO</th>\n",
       "      <th>NE-FINE-LIT</th>\n",
       "      <th>NE-FINE-METO</th>\n",
       "      <th>NE-FINE-COMP</th>\n",
       "      <th>NE-NESTED</th>\n",
       "      <th>NEL-LIT</th>\n",
       "      <th>NEL-METO</th>\n",
       "      <th>MISC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quarantaines</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>des</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ports</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>B-ent</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>Q142|Q3080569|Q16275867|Q5478259|Q294485</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>et</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Italie</td>\n",
       "      <td>B-ent</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>Q3155865|NIL|Q86253379|Q49564862|Q1961141</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>si</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nuisibles</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>au</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>commerce</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>de</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>EndOfLine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TOKEN NE-COARSE-LIT NE-COARSE-METO NE-FINE-LIT NE-FINE-METO  \\\n",
       "0   quarantaines             O              _           _            _   \n",
       "1            des             O              _           _            _   \n",
       "2          ports             O              _           _            _   \n",
       "3             de             O              _           _            _   \n",
       "4         France         B-ent              _           _            _   \n",
       "5             et             O              _           _            _   \n",
       "6              d             O              _           _            _   \n",
       "7              '             O              _           _            _   \n",
       "8         Italie         B-ent              _           _            _   \n",
       "9             si             O              _           _            _   \n",
       "10     nuisibles             O              _           _            _   \n",
       "11            au             O              _           _            _   \n",
       "12      commerce             O              _           _            _   \n",
       "13            de             O              _           _            _   \n",
       "\n",
       "   NE-FINE-COMP NE-NESTED                                    NEL-LIT NEL-METO  \\\n",
       "0             _         _                                          _        _   \n",
       "1             _         _                                          _        _   \n",
       "2             _         _                                          _        _   \n",
       "3             _         _                                          _        _   \n",
       "4             _         _   Q142|Q3080569|Q16275867|Q5478259|Q294485        _   \n",
       "5             _         _                                          _        _   \n",
       "6             _         _                                          _        _   \n",
       "7             _         _                                          _        _   \n",
       "8             _         _  Q3155865|NIL|Q86253379|Q49564862|Q1961141        _   \n",
       "9             _         _                                          _        _   \n",
       "10            _         _                                          _        _   \n",
       "11            _         _                                          _        _   \n",
       "12            _         _                                          _        _   \n",
       "13            _         _                                          _        _   \n",
       "\n",
       "            MISC  \n",
       "0              _  \n",
       "1              _  \n",
       "2              _  \n",
       "3              _  \n",
       "4              _  \n",
       "5              _  \n",
       "6   NoSpaceAfter  \n",
       "7   NoSpaceAfter  \n",
       "8              _  \n",
       "9              _  \n",
       "10             _  \n",
       "11             _  \n",
       "12             _  \n",
       "13     EndOfLine  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test=insert_links(dfs_with_predictions[1145])\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No beginning found! Token: sieur\n",
      "No beginning found! Token: 1797\n",
      "No beginning found! Token: Landeron\n",
      "No beginning found! Token: sieur\n",
      "No beginning found! Token: Neuchatel\n",
      "No beginning found! Token: Fleurier\n",
      "No beginning found! Token: Jouas\n",
      "No beginning found! Token: Lequin\n",
      "No beginning found! Token: Neuchatel\n",
      "No beginning found! Token: Stnuffer\n",
      "No beginning found! Token: Mlle\n",
      "No beginning found! Token: demoiselle\n",
      "No beginning found! Token: Crêt\n",
      "No beginning found! Token: Neuchatel\n",
      "No beginning found! Token: charpentier\n",
      "No beginning found! Token: sieur\n",
      "No beginning found! Token: Neuchatel\n",
      "No beginning found! Token: Chaumont\n",
      "No beginning found! Token: chtz\n",
      "No beginning found! Token: Ghatenay\n",
      "No beginning found! Token: secrétaire\n",
      "No beginning found! Token: l\n",
      "No beginning found! Token: de\n",
      "No beginning found! Token: Robert\n",
      "No beginning found! Token: jft\n",
      "No beginning found! Token: sieur\n",
      "No beginning found! Token: Jaques\n",
      "No beginning found! Token: Verrières\n",
      "No beginning found! Token: Cote\n",
      "No beginning found! Token: Verrières\n",
      "No beginning found! Token: de\n",
      "No beginning found! Token: Verrières\n",
      "No beginning found! Token: -\n",
      "No beginning found! Token: sieur\n",
      "No beginning found! Token: vêpre\n",
      "No beginning found! Token: demoiselle\n",
      "No beginning found! Token: du\n",
      "No beginning found! Token: damé\n",
      "No beginning found! Token: Petitpierre\n",
      "No beginning found! Token: Neuchatel\n",
      "No beginning found! Token: -\n",
      "No beginning found! Token: .\n",
      "No beginning found! Token: Neuchatel\n",
      "No beginning found! Token: Engolon\n",
      "No beginning found! Token: Villard\n",
      "No beginning found! Token: Valangin\n",
      "No beginning found! Token: Valangin\n",
      "No beginning found! Token: la\n",
      "No beginning found! Token: Perrenoud\n",
      "No beginning found! Token: Neuchatel\n",
      "No beginning found! Token: MONTES\n",
      "No beginning found! Token: voitnrier\n",
      "No beginning found! Token: AUBERJOSOIS\n",
      "No beginning found! Token: ruelle\n",
      "No beginning found! Token: nant\n",
      "No beginning found! Token: Serriere\n",
      "No beginning found! Token: g\n",
      "No beginning found! Token: Colombier\n",
      "No beginning found! Token: Bôle\n",
      "No beginning found! Token: Colombier\n",
      "No beginning found! Token: Preyla\n",
      "No beginning found! Token: Chatenaya\n",
      "No beginning found! Token: sieurs\n",
      "No beginning found! Token: Bevaix\n",
      "No beginning found! Token: Neuchatel\n",
      "No beginning found! Token: greffe\n",
      "No beginning found! Token: VENDRE\n",
      "No beginning found! Token: Colombier\n",
      "No beginning found! Token: deJusticeduditColombier\n",
      "No beginning found! Token: Racle\n",
      "No beginning found! Token: de\n",
      "No beginning found! Token: AlAL\n",
      "No beginning found! Token: Sivary\n",
      "No beginning found! Token: Juin\n",
      "No beginning found! Token: MAL\n",
      "No beginning found! Token: Al\n",
      "No beginning found! Token: Neuveville\n",
      "No beginning found! Token: Freudenreich\n",
      "No beginning found! Token: signéKocH\n",
      "No beginning found! Token: Alagistrat\n",
      "No beginning found! Token: lesecrétairc\n",
      "No beginning found! Token: VjOlE\n",
      "No beginning found! Token: ENCHÈRES\n",
      "No beginning found! Token: Gingins\n",
      "No beginning found! Token: Pillichody\n",
      "No beginning found! Token: Alercredi\n",
      "No beginning found! Token: Juin\n",
      "No beginning found! Token: Louis\n",
      "No beginning found! Token: Ponts\n",
      "No beginning found! Token: duCerfaux\n",
      "No beginning found! Token: Aleuron\n",
      "No beginning found! Token: de\n",
      "No beginning found! Token: Auvernier\n",
      "No beginning found! Token: Aîons\n",
      "No beginning found! Token: d\n",
      "No beginning found! Token: recettedeFontaine\n",
      "No beginning found! Token: Voëns\n",
      "No beginning found! Token: d\n",
      "No beginning found! Token: Liechtenhann\n",
      "No beginning found! Token: Valangin\n",
      "No beginning found! Token: kîger\n",
      "No beginning found! Token: Ostervald\n",
      "No beginning found! Token: VENDRE\n",
      "No beginning found! Token: Arrowsmith\n",
      "No beginning found! Token: Brockhaus\n",
      "No beginning found! Token: Gilbas\n",
      "No beginning found! Token: Bertuchs\n",
      "No beginning found! Token: Sieur\n",
      "No beginning found! Token: Prince\n",
      "No beginning found! Token: Principauté\n",
      "No beginning found! Token: châtelain\n",
      "No beginning found! Token: barreau\n",
      "No beginning found! Token: Alulhouse\n",
      "No beginning found! Token: Mulhouse\n",
      "No beginning found! Token: Havanne\n",
      "No beginning found! Token: Fanchette\n",
      "No beginning found! Token: Neubourg\n",
      "No beginning found! Token: Reuse\n",
      "No beginning found! Token: Marti\n",
      "No beginning found! Token: sellier\n",
      "No beginning found! Token: Gagnebin\n",
      "No beginning found! Token: Sablon\n",
      "No beginning found! Token: Annonay\n",
      "No beginning found! Token: Palerme\n",
      "No beginning found! Token: chea\n",
      "No beginning found! Token: etdescïirons\n",
      "No beginning found! Token: Colombier\n",
      "No beginning found! Token: mousseux\n",
      "No beginning found! Token: Pomard\n",
      "No beginning found! Token: Madère\n",
      "No beginning found! Token: AlAL\n",
      "No beginning found! Token: Alaille\n",
      "No beginning found! Token: Dihl\n",
      "No beginning found! Token: DeLuzc\n",
      "No beginning found! Token: Aug\n",
      "No beginning found! Token: citoyen\n",
      "No beginning found! Token: du\n",
      "No beginning found! Token: citoyen\n",
      "No beginning found! Token: Locle\n",
      "No beginning found! Token: Locle\n",
      "No beginning found! Token: Locle\n",
      "No beginning found! Token: Locle\n",
      "No beginning found! Token: citoyen\n",
      "No beginning found! Token: Uuguenin\n",
      "No beginning found! Token: Locle\n",
      "No beginning found! Token: Locle\n",
      "No beginning found! Token: Locle\n",
      "No beginning found! Token: citoyen\n",
      "No beginning found! Token: 22\n",
      "No beginning found! Token: citoyen\n",
      "No beginning found! Token: Locle\n",
      "No beginning found! Token: Philibert\n",
      "No beginning found! Token: Pcrrelet\n",
      "No beginning found! Token: Locle\n",
      "No beginning found! Token: Locle\n",
      "No beginning found! Token: ciloyen\n",
      "No beginning found! Token: Perrelet\n",
      "No beginning found! Token: Locle\n",
      "No beginning found! Token: citoyen\n",
      "No beginning found! Token: citoyen\n",
      "No beginning found! Token: Chaux\n",
      "No beginning found! Token: samedi\n",
      "No beginning found! Token: de\n",
      "No beginning found! Token: Fournier\n",
      "No beginning found! Token: Chaux\n",
      "No beginning found! Token: Chaux\n",
      "No beginning found! Token: Brot\n",
      "No beginning found! Token: Boudry\n",
      "No beginning found! Token: -\n",
      "No beginning found! Token: Norlhcole\n",
      "No beginning found! Token: Lait\n",
      "No beginning found! Token: Magdala\n",
      "No beginning found! Token: Thédoros\n",
      "No beginning found! Token: Magdala\n",
      "No beginning found! Token: àSalford\n",
      "No beginning found! Token: Salford\n",
      "No beginning found! Token: Valais\n",
      "No beginning found! Token: Haul\n",
      "No beginning found! Token: Buénos\n",
      "No beginning found! Token: Ayrcs\n",
      "No beginning found! Token: NEUCHATEL\n",
      "No beginning found! Token: dans\n",
      "No beginning found! Token: Fontainemelon\n",
      "No beginning found! Token: Fontainemclon\n",
      "No beginning found! Token: Areuse\n",
      "No beginning found! Token: Môliers\n",
      "No beginning found! Token: Areuse\n",
      "No beginning found! Token: ROME\n",
      "No beginning found! Token: Quirinal\n",
      "No beginning found! Token: ROKE\n",
      "No beginning found! Token: Le\n",
      "No beginning found! Token: ROME\n",
      "No beginning found! Token: LONDRES\n",
      "No beginning found! Token: Reichstag\n",
      "No beginning found! Token: POLA\n",
      "No beginning found! Token: Habsburg\n",
      "No beginning found! Token: Constantinople\n",
      "No beginning found! Token: SUISSE\n",
      "No beginning found! Token: Jnnod\n",
      "No beginning found! Token: Entente\n",
      "No beginning found! Token: Metallum\n",
      "No beginning found! Token: G\n",
      "No beginning found! Token: Metallum\n",
      "No beginning found! Token: z\n",
      "No beginning found! Token: 1918\n",
      "No beginning found! Token: Germanie\n",
      "No beginning found! Token: Decauville\n",
      "No beginning found! Token: Decauville\n",
      "No beginning found! Token: Schaffhouse\n",
      "No beginning found! Token: BERNE\n",
      "No beginning found! Token: VALAIS\n",
      "No beginning found! Token: de\n",
      "No beginning found! Token: FRIBOURG\n",
      "No beginning found! Token: du\n",
      "No beginning found! Token: Bulle\n",
      "No beginning found! Token: Castor\n",
      "No beginning found! Token: Mme\n",
      "No beginning found! Token: Riaz\n",
      "No beginning found! Token: commission\n",
      "No beginning found! Token: Musy\n",
      "No beginning found! Token: GENÈVE\n",
      "No beginning found! Token: conseiller\n",
      "No beginning found! Token: Lachenal\n",
      "No beginning found! Token: Etat\n",
      "No beginning found! Token: Pétermann\n",
      "No beginning found! Token: Chambres\n",
      "No beginning found! Token: Chambres\n",
      "No beginning found! Token: Confédération\n",
      "No beginning found! Token: Soleure\n",
      "No beginning found! Token: Soleure\n",
      "No beginning found! Token: Granges\n",
      "No beginning found! Token: Bravos\n",
      "No beginning found! Token: Platten\n",
      "No beginning found! Token: Feuille\n",
      "No beginning found! Token: Kellogg\n",
      "No beginning found! Token: Havas\n",
      "No beginning found! Token: York\n",
      "No beginning found! Token: Kellogg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No beginning found! Token: Kellogg\n",
      "No beginning found! Token: LONDRES\n",
      "No beginning found! Token: Havas\n",
      "No beginning found! Token: M\n",
      "No beginning found! Token: Venizelos\n",
      "No beginning found! Token: Szen\n",
      "No beginning found! Token: BELGRADE\n",
      "No beginning found! Token: Havas\n",
      "No beginning found! Token: Novosti\n",
      "No beginning found! Token: PARIS\n",
      "No beginning found! Token: Havas\n",
      "No beginning found! Token: Silésie\n",
      "No beginning found! Token: «\n",
      "No beginning found! Token: Zeitung\n",
      "No beginning found! Token: Silésie\n",
      "No beginning found! Token: Schweitnitz\n",
      "No beginning found! Token: Schweitnitz\n",
      "No beginning found! Token: Weistritz\n",
      "No beginning found! Token: Riesengebirge\n",
      "No beginning found! Token: STOCKHOLM\n",
      "No beginning found! Token: Toujquet\n",
      "No beginning found! Token: PARIS\n",
      "No beginning found! Token: Havas\n",
      "No beginning found! Token: _\n",
      "No beginning found! Token: Mme\n",
      "No beginning found! Token: Truay\n",
      "No beginning found! Token: BELGRADE\n",
      "No beginning found! Token: Avala\n",
      "No beginning found! Token: aulrèvilles\n",
      "No beginning found! Token: Havas\n",
      "No beginning found! Token: _\n",
      "No beginning found! Token: Eielson\n",
      "No beginning found! Token: COPENHAGUE\n",
      "No beginning found! Token: Havas\n",
      "No beginning found! Token: EielsOn\n",
      "No beginning found! Token: Chantoung\n",
      "No beginning found! Token: PARIS\n",
      "No beginning found! Token: Havas\n",
      "No beginning found! Token: Chantoung\n",
      "No beginning found! Token: Voyez\n",
      "No beginning found! Token: THALWIL\n",
      "No beginning found! Token: Gattikon\n",
      "No beginning found! Token: Thalwil\n",
      "No beginning found! Token: THALWIL\n",
      "No beginning found! Token: Gattikon\n",
      "No beginning found! Token: WAENGI\n",
      "No beginning found! Token: Wângi\n",
      "No beginning found! Token: Thurgovie\n",
      "No beginning found! Token: MURI\n",
      "No beginning found! Token: Bùnz\n",
      "No beginning found! Token: Argovie\n",
      "No beginning found! Token: LUCERNE\n",
      "No beginning found! Token: Neudorf\n",
      "No beginning found! Token: BREMGARTEN\n",
      "No beginning found! Token: Argovie\n",
      "No beginning found! Token: de\n",
      "No beginning found! Token: Sièrre\n",
      "No beginning found! Token: SIERRE\n",
      "No beginning found! Token: Sierre\n",
      "No beginning found! Token: Mgr\n",
      "No beginning found! Token: Sierre\n",
      "No beginning found! Token: Valais\n",
      "No beginning found! Token: bourgeoisie\n",
      "No beginning found! Token: ORBE\n",
      "No beginning found! Token: du\n",
      "No beginning found! Token: Pinfulter\n",
      "No beginning found! Token: Directoire\n",
      "No beginning found! Token: difcuflion\n",
      "No beginning found! Token: ^\n",
      "No beginning found! Token: Secretan\n",
      "No beginning found! Token: Huffi\n",
      "No beginning found! Token: Bourgeois\n",
      "No beginning found! Token: .\n",
      "No beginning found! Token: confédération\n",
      "No beginning found! Token: piyement\n",
      "No beginning found! Token: fédérale\n",
      "No beginning found! Token: Livourne\n",
      "No beginning found! Token: Bâle\n",
      "No beginning found! Token: Lucerne\n",
      "No beginning found! Token: lWrgovic\n",
      "No beginning found! Token: Thurgovie\n",
      "No beginning found! Token: Bâ\n",
      "No beginning found! Token: R\n",
      "No beginning found! Token: des\n",
      "No beginning found! Token: Soleure\n",
      "No beginning found! Token: général\n",
      "No beginning found! Token: Bâle\n",
      "No beginning found! Token: rni\n",
      "No beginning found! Token: Ge\n",
      "No beginning found! Token: Hambourg\n",
      "No beginning found! Token: PARIS\n",
      "No beginning found! Token: ChapecUlaine\n",
      "No beginning found! Token: Dubouchage\n",
      "No beginning found! Token: Fitzjaraes\n",
      "No beginning found! Token: Polignac\n",
      "No beginning found! Token: witaine\n",
      "No beginning found! Token: de\n",
      "No beginning found! Token: lonvetnent\n",
      "No beginning found! Token: Marsannè\n",
      "No beginning found! Token: ffltladt\n",
      "No beginning found! Token: \\\n",
      "No beginning found! Token: Pétion\n",
      "No beginning found! Token: tophe\n",
      "No beginning found! Token: Aiaccio\n",
      "No beginning found! Token: ESPAGNE\n",
      "No beginning found! Token: MADRID\n",
      "No beginning found! Token: Oporto\n",
      "No beginning found! Token: Oporto\n",
      "No beginning found! Token: Coïmbre\n",
      "No beginning found! Token: 1823\n",
      "No beginning found! Token: FRANCE\n",
      "No beginning found! Token: Helvétie\n",
      "No beginning found! Token: .\n",
      "No beginning found! Token: Navarin\n",
      "No beginning found! Token: Biserte\n",
      "No beginning found! Token: AFRIQUE\n",
      "No beginning found! Token: deBelidah\n",
      "No beginning found! Token: Bélidah\n",
      "No beginning found! Token: Bélidah\n",
      "No beginning found! Token: Melidja\n",
      "No beginning found! Token: CONFÉDÉRATION\n",
      "No beginning found! Token: ÉDÉIlA\n",
      "No beginning found! Token: Neuchâld\n",
      "No beginning found! Token: Confédération\n",
      "No beginning found! Token: Tessin\n",
      "No beginning found! Token: Argovie\n",
      "No beginning found! Token: Dièle\n",
      "No beginning found! Token: Luceme\n",
      "No beginning found! Token: Scliwylz\n",
      "No beginning found! Token: Glatis\n",
      "No beginning found! Token: Grisons\n",
      "No beginning found! Token: Sonderbund\n",
      "No beginning found! Token: Thurgovie\n",
      "No beginning found! Token: Solaire\n",
      "No beginning found! Token: Schaff\n",
      "No beginning found! Token: Iwtme\n",
      "No beginning found! Token: Argovie\n",
      "No beginning found! Token: Valais\n",
      "No beginning found! Token: Gerièue\n",
      "No beginning found! Token: Thurgovie\n",
      "No beginning found! Token: Gri\n",
      "No beginning found! Token: Glaris\n",
      "No beginning found! Token: Luceme\n",
      "No beginning found! Token: Neuchâlel\n",
      "No beginning found! Token: Bàle\n",
      "No beginning found! Token: Schwylz\n",
      "No beginning found! Token: Unlerwalden\n",
      "No beginning found! Token: Appenzell\n",
      "No beginning found! Token: :\n",
      "No beginning found! Token: GRISONS\n",
      "No beginning found! Token: Cornu\n",
      "No beginning found! Token: Tyrol\n",
      "No beginning found! Token: Luinbardie\n",
      "No beginning found! Token: Ponte\n",
      "No beginning found! Token: Ilots\n",
      "No beginning found! Token: BERNE\n",
      "No beginning found! Token: Vororl\n",
      "No beginning found! Token: Ochsenbeinet\n",
      "No beginning found! Token: la\n",
      "No beginning found! Token: Thiard\n",
      "No beginning found! Token: FIUBOUKG\n",
      "No beginning found! Token: JNeyruz\n",
      "No beginning found! Token: d\n",
      "No beginning found! Token: d\n",
      "No beginning found! Token: démissionnaire\n",
      "No beginning found! Token: St\n",
      "No beginning found! Token: GENÈVE\n",
      "No beginning found! Token: du\n",
      "No beginning found! Token: Tessin\n",
      "No beginning found! Token: Dièle\n",
      "No beginning found! Token: Sonderbund\n",
      "No beginning found! Token: de\n",
      "No beginning found! Token: Lucerne\n",
      "No beginning found! Token: A\n",
      "No beginning found! Token: des\n",
      "No beginning found! Token: '\n",
      "No beginning found! Token: Arau\n",
      "No beginning found! Token: LAESANMÎ\n",
      "No beginning found! Token: conseil\n",
      "No beginning found! Token: CONFÉDÉRATION\n",
      "No beginning found! Token: BERNE\n",
      "No beginning found! Token: Directoire\n",
      "No beginning found! Token: Signau\n",
      "No beginning found! Token: Konolfingen\n",
      "No beginning found! Token: Emmenthal\n",
      "No beginning found! Token: Neubaus\n",
      "No beginning found! Token: Oehsenbein\n",
      "No beginning found! Token: Slajmpfly\n",
      "No beginning found! Token: Aarberg\n",
      "No beginning found! Token: Seeland\n",
      "No beginning found! Token: Sl\n",
      "No beginning found! Token: Tessin\n",
      "No beginning found! Token: Bellinzone\n",
      "No beginning found! Token: et\n",
      "No beginning found! Token: Schwyiz\n",
      "No beginning found! Token: Inspruck\n",
      "No beginning found! Token: Messine\n",
      "No beginning found! Token: Païenne\n",
      "No beginning found! Token: soldatserrans\n",
      "No beginning found! Token: faubourg\n",
      "No beginning found! Token: Gazzi\n",
      "No beginning found! Token: Conlessa\n",
      "No beginning found! Token: Calania\n",
      "No beginning found! Token: Gonzenbacb\n",
      "No beginning found! Token: Zwiki\n",
      "No beginning found! Token: Diernwachter\n",
      "No beginning found! Token: Vorort\n",
      "No beginning found! Token: Francfort\n",
      "No beginning found! Token: avec\n",
      "No beginning found! Token: Confédération\n",
      "No beginning found! Token: Lombardie\n",
      "No beginning found! Token: Directoire\n",
      "No beginning found! Token: Konitz\n",
      "No beginning found! Token: Ochsenbein\n",
      "No beginning found! Token: Funek\n",
      "No beginning found! Token: Imobersteg\n",
      "No beginning found! Token: Neuhaus\n",
      "No beginning found! Token: resle\n",
      "No beginning found! Token: Neuchàtel\n",
      "No beginning found! Token: FRANGE\n",
      "No beginning found! Token: lord\n",
      "No beginning found! Token: d\n",
      "No beginning found! Token: Indépendance\n",
      "No beginning found! Token: Moldavie\n",
      "No beginning found! Token: Valachie\n",
      "No beginning found! Token: Galignani\n",
      "No beginning found! Token: diton\n",
      "No beginning found! Token: Simoda\n",
      "No beginning found! Token: gendre\n",
      "No beginning found! Token: Moniteur\n",
      "No beginning found! Token: GAZETTE\n",
      "No beginning found! Token: Niel\n",
      "No beginning found! Token: Biarritz\n",
      "No beginning found! Token: i\n",
      "No beginning found! Token: Constitutionnel\n",
      "No beginning found! Token: Conslitutionnel\n",
      "No beginning found! Token: Biarritz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No beginning found! Token: Lanterne\n",
      "No beginning found! Token: Avis\n",
      "No beginning found! Token: Walewski\n",
      "No beginning found! Token: bachelier\n",
      "No beginning found! Token: procureur\n",
      "No beginning found! Token: catholicisme\n",
      "No beginning found! Token: Moniteur\n",
      "No beginning found! Token: Prusse\n",
      "No beginning found! Token: Mayence\n",
      "No beginning found! Token: Diable\n",
      "No beginning found! Token: Quatre\n",
      "No beginning found! Token: Lanterne\n",
      "No beginning found! Token: La\n",
      "No beginning found! Token: oonlre\n",
      "No beginning found! Token: Prusse\n",
      "No beginning found! Token: Prusse\n",
      "No beginning found! Token: Prusse\n",
      "No beginning found! Token: Nouvelliste\n",
      "No beginning found! Token: Bohême\n",
      "No beginning found! Token: de\n",
      "No beginning found! Token: Gallicie\n",
      "No beginning found! Token: landwehr\n",
      "No beginning found! Token: de\n",
      "No beginning found! Token: Bohême\n",
      "No beginning found! Token: Havane\n",
      "No beginning found! Token: d\n",
      "No beginning found! Token: de\n",
      "No beginning found! Token: Moudon\n",
      "No beginning found! Token: Chàtillens\n",
      "No beginning found! Token: Palézieux\n",
      "No beginning found! Token: Palézieux\n",
      "No beginning found! Token: Bouveret\n",
      "No beginning found! Token: Evionnaz\n",
      "No beginning found! Token: Valais\n",
      "No beginning found! Token: Jougne\n",
      "No beginning found! Token: .\n",
      "No beginning found! Token: royalistes\n",
      "No beginning found! Token: Laisant\n",
      "No beginning found! Token: Vergoin\n",
      "No beginning found! Token: boulangisme\n",
      "No beginning found! Token: gendre\n",
      "No beginning found! Token: Baudin\n",
      "No beginning found! Token: BERNE\n",
      "No beginning found! Token: à\n",
      "No beginning found! Token: ARGOVIE\n",
      "No beginning found! Token: Bàle\n",
      "No beginning found! Token: Rheinfelden\n",
      "No beginning found! Token: VALAIS\n",
      "No beginning found! Token: Tourtemagne\n",
      "No beginning found! Token: Tourtemagne\n",
      "No beginning found! Token: GENÈVE\n",
      "No beginning found! Token: Barret\n",
      "No beginning found! Token: Calame\n",
      "No beginning found! Token: Genoud\n",
      "No beginning found! Token: Terrier\n",
      "No beginning found! Token: SUISSE\n",
      "No beginning found! Token: à\n",
      "No beginning found! Token: Bernina\n",
      "No beginning found! Token: Bernina\n",
      "No beginning found! Token: Tirano\n",
      "No beginning found! Token: Poschiavo\n",
      "No beginning found! Token: Bâle\n",
      "No beginning found! Token: Winterthour\n",
      "No beginning found! Token: Righi\n",
      "No beginning found! Token: Sœntis\n",
      "No beginning found! Token: Gothard\n",
      "No beginning found! Token: Pilate\n",
      "No beginning found! Token: Prusse\n",
      "No beginning found! Token: Bâle\n",
      "No beginning found! Token: Hambourg\n",
      "No beginning found! Token: de\n",
      "No beginning found! Token: Montdidier\n",
      "No beginning found! Token: Noyon\n",
      "No beginning found! Token: llaiïïea\n",
      "No beginning found! Token: Avre\n",
      "No beginning found! Token: BofUot\n",
      "No beginning found! Token: Ohomin\n",
      "No beginning found! Token: BoveHe\n",
      "No beginning found! Token: Londires\n",
      "No beginning found! Token: Bobecq\n",
      "No beginning found! Token: vallées\n",
      "No beginning found! Token: Ancre\n",
      "No beginning found! Token: Bétliuno\n",
      "No beginning found! Token: Nleppe\n",
      "No beginning found! Token: surVouest\n",
      "No beginning found! Token: Morlancourt\n",
      "No beginning found! Token: Kemnraï\n",
      "No beginning found! Token: Flandres\n",
      "No beginning found! Token: Fartiïïerie\n",
      "No beginning found! Token: Flandres\n",
      "No beginning found! Token: Sandes\n",
      "No beginning found! Token: Dlckebusche\n",
      "No beginning found! Token: WSONT\n",
      "No beginning found! Token: Kemmel\n",
      "No beginning found! Token: Kemmel\n",
      "No beginning found! Token: Scarpe\n",
      "No beginning found! Token: Bucquoy\n",
      "No beginning found! Token: Ancre\n",
      "No beginning found! Token: Conbie\n",
      "No beginning found! Token: VJMers\n",
      "No beginning found! Token: Luoe\n",
      "No beginning found! Token: Avre\n",
      "No beginning found! Token: Avre\n",
      "No beginning found! Token: Fenneml\n",
      "No beginning found! Token: Borne\n",
      "No beginning found! Token: Corno\n",
      "No beginning found! Token: Valknnsa\n",
      "No beginning found! Token: Pasubio\n",
      "No beginning found! Token: molano\n",
      "No beginning found! Token: Alano\n",
      "No beginning found! Token: Piave\n",
      "No beginning found! Token: Soreslano\n",
      "No beginning found! Token: Piave\n",
      "No beginning found! Token: Kemmel\n",
      "No beginning found! Token: Moreuil\n",
      "No beginning found! Token: autte\n",
      "No beginning found! Token: Dawes\n",
      "No beginning found! Token: Etats\n",
      "No beginning found! Token: Cest\n",
      "No beginning found! Token: Valais\n",
      "No beginning found! Token: libéralisme\n",
      "No beginning found! Token: Sarrebruck\n",
      "No beginning found! Token: Sarrebruck\n",
      "No beginning found! Token: Ethiopie\n",
      "No beginning found! Token: Dune\n",
      "No beginning found! Token: AIGLE\n",
      "No beginning found! Token: .\n",
      "No beginning found! Token: Tilleul\n",
      "No beginning found! Token: Ecole\n",
      "No beginning found! Token: 1933\n",
      "No beginning found! Token: Chevillard\n",
      "No beginning found! Token: 1931\n",
      "No beginning found! Token: Ecole\n",
      "No beginning found! Token: 1935\n",
      "No beginning found! Token: 1935\n",
      "No beginning found! Token: BEX\n",
      "No beginning found! Token: Bralschi\n",
      "No beginning found! Token: Nicollerat\n",
      "No beginning found! Token: Soutier\n",
      "No beginning found! Token: Favrod\n",
      "No beginning found! Token: Zumbrunnen\n",
      "No beginning found! Token: Sollberger\n",
      "No beginning found! Token: Solalex\n",
      "No beginning found! Token: Bex\n",
      "No beginning found! Token: Société\n",
      "No beginning found! Token: Renens\n",
      "No beginning found! Token: Chavannes\n",
      "No beginning found! Token: Clardon\n",
      "No beginning found! Token: Ecublens\n",
      "No beginning found! Token: Moraz\n",
      "No beginning found! Token: Crissier\n",
      "No beginning found! Token: Christin\n",
      "No beginning found! Token: Clardon\n",
      "No beginning found! Token: taire\n",
      "No beginning found! Token: Coderey\n",
      "No beginning found! Token: Renens\n",
      "No beginning found! Token: Chavannes\n",
      "No beginning found! Token: Ecublens\n",
      "No beginning found! Token: Crissier\n",
      "No beginning found! Token: Renens\n",
      "No beginning found! Token: Châtelard\n",
      "No beginning found! Token: Châtelard\n",
      "No beginning found! Token: Confédération\n",
      "No beginning found! Token: ICHA\n",
      "No beginning found! Token: LONDRES\n",
      "No beginning found! Token: BRI\n",
      "No beginning found! Token: BRI\n",
      "No beginning found! Token: BRI\n",
      "No beginning found! Token: Aile\n",
      "No beginning found! Token: magne\n",
      "No beginning found! Token: Schlumberger\n",
      "No beginning found! Token: Morand\n",
      "No beginning found! Token: Morand\n",
      "No beginning found! Token: Chateaubriand\n",
      "No beginning found! Token: Morand\n",
      "No beginning found! Token: Morand\n",
      "No beginning found! Token: Paulhan\n",
      "No beginning found! Token: Proust\n",
      "No beginning found! Token: Schlumberger\n",
      "No beginning found! Token: Schlumberger\n",
      "No beginning found! Token: Gide\n",
      "No beginning found! Token: NRF\n",
      "No beginning found! Token: Ramuz\n",
      "No beginning found! Token: Pacificos\n",
      "No beginning found! Token: Villacorte\n",
      "No beginning found! Token: Euscbio\n",
      "No beginning found! Token: Eusebio\n",
      "No beginning found! Token: Paris\n",
      "No beginning found! Token: totalitarisme\n",
      "No beginning found! Token: Nobel\n",
      "No beginning found! Token: Armel\n",
      "No beginning found! Token: Kawabata\n",
      "No beginning found! Token: Sarraute\n",
      "No beginning found! Token: Robbe\n",
      "No beginning found! Token: Kawabata\n",
      "No beginning found! Token: Kawabata\n",
      "No beginning found! Token: Nobel\n",
      "No beginning found! Token: Israélien\n",
      "No beginning found! Token: Guatémaltèque\n",
      "No beginning found! Token: Japonais\n",
      "No beginning found! Token: Thonon\n",
      "No beginning found! Token: Municipalité\n",
      "No beginning found! Token: Thonon\n",
      "No beginning found! Token: Municipalité\n",
      "No beginning found! Token: Trehard\n",
      "No beginning found! Token: dramatique\n",
      "No beginning found! Token: Alwin\n",
      "No beginning found! Token: Rauschcnberg\n",
      "No beginning found! Token: Rauschenberg\n",
      "No beginning found! Token: Maeght\n",
      "No beginning found! Token: Stahly\n",
      "No beginning found! Token: Giraudoux\n",
      "No beginning found! Token: Piaf\n",
      "No beginning found! Token: Montand\n",
      "No beginning found! Token: Gréco\n",
      "No beginning found! Token: Bobino\n",
      "No beginning found! Token: Tchou\n",
      "No beginning found! Token: étrangères\n",
      "No beginning found! Token: Proche\n",
      "No beginning found! Token: Etats\n",
      "No beginning found! Token: israélien\n",
      "No beginning found! Token: Cisjordanie\n",
      "No beginning found! Token: Etats\n",
      "No beginning found! Token: Nastassia\n",
      "No beginning found! Token: ATS\n",
      "No beginning found! Token: Nastassia\n",
      "No beginning found! Token: Nastassia\n",
      "No beginning found! Token: Nastassia\n",
      "No beginning found! Token: CICR\n",
      "No beginning found! Token: FRANCE\n",
      "No beginning found! Token: irisien\n",
      "No beginning found! Token: Guillard\n",
      "No beginning found! Token: ALLEMAGNE\n",
      "No beginning found! Token: Reindel\n",
      "No beginning found! Token: iJKeaz\n",
      "No beginning found! Token: ijeau\n",
      "No beginning found! Token: Piappi\n",
      "No beginning found! Token: Reindel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No beginning found! Token: Hambour\n",
      "No beginning found! Token: Mailau\n",
      "No beginning found! Token: RUSSIE\n",
      "No beginning found! Token: Bosdani\n",
      "No beginning found! Token: Mauseï\n",
      "No beginning found! Token: Vilna\n",
      "No beginning found! Token: Soboline\n",
      "No beginning found! Token: ANGLETERRE\n",
      "No beginning found! Token: Devinez\n",
      "No beginning found! Token: Eài\n",
      "No beginning found! Token: JOUR\n",
      "No beginning found! Token: Tchécoslovaquie\n",
      "No beginning found! Token: Godesberg\n",
      "No beginning found! Token: Godesberg\n",
      "No beginning found! Token: de\n",
      "No beginning found! Token: chancelier\n",
      "No beginning found! Token: Tchécoslovaquie\n",
      "No beginning found! Token: Fuhrer\n",
      "No beginning found! Token: Tchécoslovaquie\n",
      "No beginning found! Token: Sapin\n",
      "No beginning found! Token: Sapin\n",
      "No beginning found! Token: Motta\n",
      "No beginning found! Token: Rodolphe\n",
      "No beginning found! Token: Chaudet\n",
      "No beginning found! Token: au\n",
      "No beginning found! Token: Chaudet\n",
      "No beginning found! Token: Jean\n",
      "No beginning found! Token: IMPARTIAL\n",
      "No beginning found! Token: Libye\n",
      "No beginning found! Token: dissident\n",
      "No beginning found! Token: Abou\n",
      "No beginning found! Token: Benghazi\n",
      "No beginning found! Token: Libye\n",
      "No beginning found! Token: Istres\n",
      "No beginning found! Token: APPEL\n",
      "No beginning found! Token: Beyrouth\n",
      "No beginning found! Token: dirigeant\n",
      "No beginning found! Token: Mme\n",
      "No beginning found! Token: Valente\n",
      "No beginning found! Token: Beyrouth\n",
      "No beginning found! Token: ats\n",
      "No beginning found! Token: Proche\n",
      "No beginning found! Token: Proche\n",
      "No beginning found! Token: palestinien\n",
      "No beginning found! Token: Golan\n",
      "No beginning found! Token: Yasser\n",
      "No beginning found! Token: Cisjordanie\n",
      "No beginning found! Token: Cisjordanie\n",
      "No beginning found! Token: afp\n",
      "No beginning found! Token: Hambourg\n",
      "No beginning found! Token: Pékin\n",
      "No beginning found! Token: le\n",
      "No beginning found! Token: Breuleux\n",
      "No beginning found! Token: Daid\n",
      "No beginning found! Token: compatriote\n",
      "No beginning found! Token: ,\n",
      "No beginning found! Token: Timofeeva\n",
      "No beginning found! Token: la\n",
      "No beginning found! Token: Le\n",
      "No beginning found! Token: ses\n",
      "No beginning found! Token: Biwott\n",
      "No beginning found! Token: Roumaine\n",
      "No beginning found! Token: STÉPHANE\n",
      "No beginning found! Token: BNS\n",
      "No beginning found! Token: ’\n",
      "No beginning found! Token: BNS\n",
      "No beginning found! Token: ’\n",
      "No beginning found! Token: ’\n",
      "No beginning found! Token: BNS\n",
      "No beginning found! Token: BNS\n",
      "No beginning found! Token: l\n",
      "No beginning found! Token: l\n",
      "No beginning found! Token: BNS\n",
      "No beginning found! Token: la\n",
      "No beginning found! Token: BNS\n",
      "No beginning found! Token: BNS\n",
      "No beginning found! Token: ats\n",
      "No beginning found! Token: DONALD\n",
      "No beginning found! Token: ’\n",
      "No beginning found! Token: Etats\n",
      "No beginning found! Token: Etats\n",
      "No beginning found! Token: Haïti\n",
      "No beginning found! Token: Etats\n",
      "No beginning found! Token: Sénégal\n"
     ]
    }
   ],
   "source": [
    "dfs_with_links = [insert_links(df) for df in dfs_with_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOKEN</th>\n",
       "      <th>NE-COARSE-LIT</th>\n",
       "      <th>NE-COARSE-METO</th>\n",
       "      <th>NE-FINE-LIT</th>\n",
       "      <th>NE-FINE-METO</th>\n",
       "      <th>NE-FINE-COMP</th>\n",
       "      <th>NE-NESTED</th>\n",
       "      <th>NEL-LIT</th>\n",
       "      <th>NEL-METO</th>\n",
       "      <th>MISC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moyens</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>opposition</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>à</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>apporter</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>à</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>la</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dite</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>demande</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>eh</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>EndOfLine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TOKEN NE-COARSE-LIT NE-COARSE-METO NE-FINE-LIT NE-FINE-METO  \\\n",
       "0       moyens             O              _           _            _   \n",
       "1            d             O              _           _            _   \n",
       "2            '             O              _           _            _   \n",
       "3   opposition             O              _           _            _   \n",
       "4            à             O              _           _            _   \n",
       "5     apporter             O              _           _            _   \n",
       "6            à             O              _           _            _   \n",
       "7           la             O              _           _            _   \n",
       "8         dite             O              _           _            _   \n",
       "9      demande             O              _           _            _   \n",
       "10          eh             O              _           _            _   \n",
       "\n",
       "   NE-FINE-COMP NE-NESTED NEL-LIT NEL-METO          MISC  \n",
       "0             _         _       _        _             _  \n",
       "1             _         _       _        _  NoSpaceAfter  \n",
       "2             _         _       _        _  NoSpaceAfter  \n",
       "3             _         _       _        _             _  \n",
       "4             _         _       _        _             _  \n",
       "5             _         _       _        _             _  \n",
       "6             _         _       _        _             _  \n",
       "7             _         _       _        _             _  \n",
       "8             _         _       _        _             _  \n",
       "9             _         _       _        _             _  \n",
       "10            _         _       _        _     EndOfLine  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_with_links[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "run_name = OUTPUT_PATH.split('/')[-1]\n",
    "folder = OUTPUT_PATH.split('/')[0]\n",
    "pickle_path = folder + '/pickles/' + run_name + '.p'\n",
    "\n",
    "pickle.dump(dfs_with_links, open(pickle_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_results(dfs_with_links, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTEST_bundle2_FR_1 – no Europeana yet, 10 epochs\\nTEST_bundle2_FR_2 – with Europeana, 5 epochs\\nTEST_bundle2_FR_3 – no Europeana, 5 epochs - just to compare\\n\\nTEST_bundle2_FR_4 – no Europeana, 8 epochs (it was the best for FR so far)\\nTEST_bundle2_FR_5 – with Europeana, 8 epochs - is it better? probably yes!\\n\\nTEST_bundle2_DE_2 – with Europeana, 5 epochs\\nTEST_bundle2_DE_3 – no Europeana, 7 epochs\\nTEST_bundle4_DE_4 – with Europeana, 7 epochs\\n\\n\\nTEST_bundle2_EN_1 – BERT finetuned on conll English \\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "TEST_bundle2_FR_1 – no Europeana yet, 10 epochs\n",
    "TEST_bundle2_FR_2 – with Europeana, 5 epochs\n",
    "TEST_bundle2_FR_3 – no Europeana, 5 epochs - just to compare\n",
    "\n",
    "TEST_bundle2_FR_4 – no Europeana, 8 epochs (it was the best for FR so far)\n",
    "TEST_bundle2_FR_5 – with Europeana, 8 epochs - is it better? probably yes!\n",
    "\n",
    "TEST_bundle2_DE_2 – with Europeana, 5 epochs\n",
    "TEST_bundle2_DE_3 – no Europeana, 7 epochs\n",
    "TEST_bundle4_DE_4 – with Europeana, 7 epochs\n",
    "\n",
    "\n",
    "TEST_bundle2_EN_1 – BERT finetuned on conll English \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (transformers)",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
