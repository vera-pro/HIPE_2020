{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage: specify the parameters in the config dictionary below.\\\n",
    "Model options here are the following: \"vera-pro/bert-mention-de\", \"vera-pro/bert-mention-fr\" and \"vera-pro/bert-mention-en\". Alternatively, you can train your own transformer model (and probably achieve better results than I did right before the deadline :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_path': \"data/test_bundle2/HIPE-data-v1.2-test-masked-de.tsv\",\n",
    "    'model': \"vera-pro/bert-mention-de\",\n",
    "    'tokenizer': \"bert-base-multilingual-cased\",\n",
    "    'output_path': \"results/mention_detection.tsv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = config['input_path']\n",
    "\n",
    "MODEL = config['model']\n",
    "\n",
    "TOKENIZER = config['tokenizer']\n",
    "\n",
    "OUTPUT_PATH = config['output_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0: reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_processing import read_data_to_dfs, write_results, add_beginnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = read_data_to_dfs(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOKEN</th>\n",
       "      <th>NE-COARSE-LIT</th>\n",
       "      <th>NE-COARSE-METO</th>\n",
       "      <th>NE-FINE-LIT</th>\n",
       "      <th>NE-FINE-METO</th>\n",
       "      <th>NE-FINE-COMP</th>\n",
       "      <th>NE-NESTED</th>\n",
       "      <th>NEL-LIT</th>\n",
       "      <th>NEL-METO</th>\n",
       "      <th>MISC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>die</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neulich</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>schon</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>erzählten</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vorfälle</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rom</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ans</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>EndOfLine|NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Directorium</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>berichtet</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>,</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>und</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>die</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>verdächtige</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Weise</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>,</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>EndOfLine|NoSpaceAfter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TOKEN NE-COARSE-LIT NE-COARSE-METO NE-FINE-LIT NE-FINE-METO  \\\n",
       "0           die             _              _           _            _   \n",
       "1       neulich             _              _           _            _   \n",
       "2         schon             _              _           _            _   \n",
       "3     erzählten             _              _           _            _   \n",
       "4      Vorfälle             _              _           _            _   \n",
       "5            in             _              _           _            _   \n",
       "6           Rom             _              _           _            _   \n",
       "7           ans             _              _           _            _   \n",
       "8   Directorium             _              _           _            _   \n",
       "9     berichtet             _              _           _            _   \n",
       "10            ,             _              _           _            _   \n",
       "11          und             _              _           _            _   \n",
       "12          die             _              _           _            _   \n",
       "13  verdächtige             _              _           _            _   \n",
       "14        Weise             _              _           _            _   \n",
       "15            ,             _              _           _            _   \n",
       "\n",
       "   NE-FINE-COMP NE-NESTED NEL-LIT NEL-METO                    MISC  \n",
       "0             _         _       _        _                       _  \n",
       "1             _         _       _        _                       _  \n",
       "2             _         _       _        _                       _  \n",
       "3             _         _       _        _                       _  \n",
       "4             _         _       _        _                       _  \n",
       "5             _         _       _        _                       _  \n",
       "6             _         _       _        _                       _  \n",
       "7             _         _       _        _  EndOfLine|NoSpaceAfter  \n",
       "8             _         _       _        _                       _  \n",
       "9             _         _       _        _            NoSpaceAfter  \n",
       "10            _         _       _        _                       _  \n",
       "11            _         _       _        _                       _  \n",
       "12            _         _       _        _                       _  \n",
       "13            _         _       _        _                       _  \n",
       "14            _         _       _        _            NoSpaceAfter  \n",
       "15            _         _       _        _  EndOfLine|NoSpaceAfter  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# data = OUTPUT_PATH.split('/')[-1]\n",
    "# pickle_path = 'pickles/' + data + '.p'\n",
    "\n",
    "# pickle.dump(dfs, open(pickle_path, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Mention detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER)\n",
    "\n",
    "label_list = [\n",
    "    'B-ent',\n",
    "    'I-ent',\n",
    "    'O'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(sequence):\n",
    "    tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n",
    "    inputs = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "\n",
    "    # print([(a, b) for a, b in (zip(tokens,inputs[0]))])\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    # print(outputs)\n",
    "    predictions = torch.argmax(outputs[0], dim=2)\n",
    "\n",
    "    nice_predictions = [(token, label_list[prediction]) for token, prediction in zip(tokens, predictions[0].tolist())]\n",
    "    return nice_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize_predictions(predictions):\n",
    "    cur_token = ''\n",
    "    cur_label = ''\n",
    "    res = []\n",
    "    for token, label in predictions:\n",
    "        if token[0] == '[': # or (len(token) == 1 and not token.isalpha()):\n",
    "            continue\n",
    "        if token[0] == '#':\n",
    "            cur_token += token.strip('#')\n",
    "            cur_label = label\n",
    "        else:\n",
    "            if cur_token:\n",
    "                res.append((cur_token, cur_label))\n",
    "            cur_token = token\n",
    "            cur_label = label\n",
    "            \n",
    "    if cur_token:\n",
    "        res.append((cur_token, cur_label))        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_df(df):\n",
    "    sequence = \" \".join(df['TOKEN'].tolist())\n",
    "    \n",
    "    predictions_raw = get_predictions(sequence)\n",
    "#     print(predictions_raw)\n",
    "    predictions = detokenize_predictions(predictions_raw)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('warme', 'O'),\n",
       " (',', 'O'),\n",
       " ('wohltuende', 'O'),\n",
       " (',', 'O'),\n",
       " ('menschliche', 'O'),\n",
       " ('Worte', 'O'),\n",
       " ('sind', 'O'),\n",
       " ('es', 'O'),\n",
       " ('.', 'O'),\n",
       " ('mit', 'O')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_for_df(dfs[-100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions_to_df(df, target_column='NE-COARSE-LIT'):\n",
    "    predictions = predict_for_df(df)\n",
    "    \n",
    "    res_df = df.copy()\n",
    "    for i, (token, label) in enumerate(predictions):\n",
    "        res_df[target_column][i] = label\n",
    "        \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_processing import add_beginnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_with_predictions = [add_beginnings(add_predictions_to_df(df)) for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_with_predictions = [add_predictions_to_df(df) for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOKEN</th>\n",
       "      <th>NE-COARSE-LIT</th>\n",
       "      <th>NE-COARSE-METO</th>\n",
       "      <th>NE-FINE-LIT</th>\n",
       "      <th>NE-FINE-METO</th>\n",
       "      <th>NE-FINE-COMP</th>\n",
       "      <th>NE-NESTED</th>\n",
       "      <th>NEL-LIT</th>\n",
       "      <th>NEL-METO</th>\n",
       "      <th>MISC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beitslosigkeit</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hineinpaßt</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Er</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bringt</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ferner</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>einige</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>EndOfLine|NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wünsche</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bezug</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>auf</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>die</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Unterstützung</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>der</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kranken</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>¬</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>EndOfLine|NoSpaceAfter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TOKEN NE-COARSE-LIT NE-COARSE-METO NE-FINE-LIT NE-FINE-METO  \\\n",
       "0   beitslosigkeit             O              _           _            _   \n",
       "1       hineinpaßt             O              _           _            _   \n",
       "2                .             O              _           _            _   \n",
       "3               Er             O              _           _            _   \n",
       "4           bringt             O              _           _            _   \n",
       "5           ferner             O              _           _            _   \n",
       "6           einige             O              _           _            _   \n",
       "7          Wünsche             O              _           _            _   \n",
       "8               in             O              _           _            _   \n",
       "9            bezug             O              _           _            _   \n",
       "10             auf             O              _           _            _   \n",
       "11             die             O              _           _            _   \n",
       "12   Unterstützung             O              _           _            _   \n",
       "13             der             O              _           _            _   \n",
       "14         Kranken             O              _           _            _   \n",
       "15               ¬             O              _           _            _   \n",
       "\n",
       "   NE-FINE-COMP NE-NESTED NEL-LIT NEL-METO                    MISC  \n",
       "0             _         _       _        _                       _  \n",
       "1             _         _       _        _            NoSpaceAfter  \n",
       "2             _         _       _        _                       _  \n",
       "3             _         _       _        _                       _  \n",
       "4             _         _       _        _                       _  \n",
       "5             _         _       _        _                       _  \n",
       "6             _         _       _        _  EndOfLine|NoSpaceAfter  \n",
       "7             _         _       _        _                       _  \n",
       "8             _         _       _        _                       _  \n",
       "9             _         _       _        _                       _  \n",
       "10            _         _       _        _                       _  \n",
       "11            _         _       _        _                       _  \n",
       "12            _         _       _        _                       _  \n",
       "13            _         _       _        _                       _  \n",
       "14            _         _       _        _            NoSpaceAfter  \n",
       "15            _         _       _        _  EndOfLine|NoSpaceAfter  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_with_predictions[1003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[CLS]', 'O'),\n",
       " ('John', 'B-ent'),\n",
       " ('Sm', 'I-ent'),\n",
       " ('##it', 'I-ent'),\n",
       " ('and', 'O'),\n",
       " ('Maurice', 'B-ent'),\n",
       " ('Bourgoin', 'I-ent'),\n",
       " ('[SEP]', 'O')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions('John Smit and Maurice Bourgoin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOKEN</th>\n",
       "      <th>NE-COARSE-LIT</th>\n",
       "      <th>NE-COARSE-METO</th>\n",
       "      <th>NE-FINE-LIT</th>\n",
       "      <th>NE-FINE-METO</th>\n",
       "      <th>NE-FINE-COMP</th>\n",
       "      <th>NE-NESTED</th>\n",
       "      <th>NEL-LIT</th>\n",
       "      <th>NEL-METO</th>\n",
       "      <th>MISC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reichs</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schutz</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>und</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beystand</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>erflehten</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sehr</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dringend</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>EndOfLine|NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>„</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>und</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>derb</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abgewiesen</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>NoSpaceAfter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>und</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vom</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ganzen</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Vorhaben</td>\n",
       "      <td>O</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>EndOfLine|NoSpaceAfter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TOKEN NE-COARSE-LIT NE-COARSE-METO NE-FINE-LIT NE-FINE-METO  \\\n",
       "0       reichs             O              _           _            _   \n",
       "1       Schutz             O              _           _            _   \n",
       "2          und             O              _           _            _   \n",
       "3     Beystand             O              _           _            _   \n",
       "4    erflehten             O              _           _            _   \n",
       "5         sehr             O              _           _            _   \n",
       "6     dringend             O              _           _            _   \n",
       "7            „             O              _           _            _   \n",
       "8          und             O              _           _            _   \n",
       "9         derb             O              _           _            _   \n",
       "10  abgewiesen             O              _           _            _   \n",
       "11           ,             O              _           _            _   \n",
       "12         und             O              _           _            _   \n",
       "13         vom             O              _           _            _   \n",
       "14      ganzen             O              _           _            _   \n",
       "15    Vorhaben             O              _           _            _   \n",
       "\n",
       "   NE-FINE-COMP NE-NESTED NEL-LIT NEL-METO                    MISC  \n",
       "0             _         _       _        _                       _  \n",
       "1             _         _       _        _                       _  \n",
       "2             _         _       _        _                       _  \n",
       "3             _         _       _        _                       _  \n",
       "4             _         _       _        _                       _  \n",
       "5             _         _       _        _                       _  \n",
       "6             _         _       _        _  EndOfLine|NoSpaceAfter  \n",
       "7             _         _       _        _            NoSpaceAfter  \n",
       "8             _         _       _        _                       _  \n",
       "9             _         _       _        _                       _  \n",
       "10            _         _       _        _            NoSpaceAfter  \n",
       "11            _         _       _        _                       _  \n",
       "12            _         _       _        _                       _  \n",
       "13            _         _       _        _                       _  \n",
       "14            _         _       _        _                       _  \n",
       "15            _         _       _        _  EndOfLine|NoSpaceAfter  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_with_predictions[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# run_name = OUTPUT_PATH.split('/')[-1]\n",
    "# folder = OUTPUT_PATH.split('/')[0]\n",
    "# pickle_path = folder + '/pickles/' + run_name + '.p'\n",
    "\n",
    "# pickle.dump(dfs_with_predictions, open(pickle_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_results(dfs_with_predictions, OUTPUT_PATH)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (transformers)",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
